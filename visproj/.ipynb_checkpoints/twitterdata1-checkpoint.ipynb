{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intro stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "consumer_key = \"U6eIfx0myrDZxymjY6rxFQuH3\"\n",
    "consumer_secret = \"bmHWK7d1ktxIa43iOar1eyPs2kG9frLFecv0E6mdYWXex3VCnM\"\n",
    "access_token = \"1351114116291842050-Sqx8kbMr7mVneQasWdjkrj9CH4NfI8\"\n",
    "access_token_secret = \"VfmTCgDjmPRAQ7vwGMysI6izKnvgPSrRqqO035ZPxDIPT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['created_at', 'id', 'id_str', 'text', 'truncated', 'entities', 'source', 'in_reply_to_status_id', 'in_reply_to_status_id_str', 'in_reply_to_user_id', 'in_reply_to_user_id_str', 'in_reply_to_screen_name', 'user', 'geo', 'coordinates', 'place', 'contributors', 'is_quote_status', 'retweet_count', 'favorite_count', 'favorited', 'retweeted', 'lang'])\n"
     ]
    }
   ],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())\n",
    "\n",
    "public_tweets = api.home_timeline()\n",
    "for tweet in public_tweets:\n",
    "    print(tweet.keys())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get first tweets from topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlp = api.search(\"abb\", count = 10, lang = \"sv\")\n",
    "len(xlp[\"statuses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kunal Sharma : @ayeajanabi Kiska kata abb?\n",
      "################\n",
      "Kunal Sharma\n",
      "Kars : @BengtHojer Bist√•nd √§r mutor, kr√§vs motprestation som √§r att k√∂pa, kraftf√∂rs√∂rjning ABB och tele infrastruktur Eric‚Ä¶ https://t.co/rPL99sAOXk\n",
      "################\n",
      "Kars\n",
      "Harsh (shehnaazGill meri sweetheart) ‚ù§üòç : RT @Mithoo1290: Ignore mat karna abb ü•∫üôè https://t.co/OGWvf0ebt5\n",
      "################\n",
      "Harsh (shehnaazGill meri sweetheart) ‚ù§üòç\n",
      "Dr Anvesa Chaudhary : RT @Mithoo1290: Ignore mat karna abb ü•∫üôè https://t.co/OGWvf0ebt5\n",
      "################\n",
      "Dr Anvesa Chaudhary\n",
      "ùêåùê¢ùê≠ùê°ùê®ùê®üñ§ü•Ä|| Shehnaaz ‚ô° : Ignore mat karna abb ü•∫üôè https://t.co/OGWvf0ebt5\n",
      "################\n",
      "ùêåùê¢ùê≠ùê°ùê®ùê®üñ§ü•Ä|| Shehnaaz ‚ô°\n",
      "Jotüíï : Ignore mat karna abb üôè https://t.co/msJLRtyWLs\n",
      "################\n",
      "Jotüíï\n",
      "Pranvi : RT @Nelson_04_: @SafeedBandarya Ohh big fan abb tweet rt karr\n",
      "\n",
      "FOREVER WITH RKV\n",
      "################\n",
      "Pranvi\n",
      "Sandesh Uparkoti : RT @Nelson_04_: @SafeedBandarya Ohh big fan abb tweet rt karr\n",
      "\n",
      "FOREVER WITH RKV\n",
      "################\n",
      "Sandesh Uparkoti\n",
      "Priyp : RT @Nelson_04_: @SafeedBandarya Ohh big fan abb tweet rt karr\n",
      "\n",
      "FOREVER WITH RKV\n",
      "################\n",
      "Priyp\n",
      "Safeed Bandariyaüôà(Sanskari trollerüòèüòé) : RT @Nelson_04_: @SafeedBandarya Ohh big fan abb tweet rt karr\n",
      "\n",
      "FOREVER WITH RKV\n",
      "################\n",
      "Safeed Bandariyaüôà(Sanskari trollerüòèüòé)\n"
     ]
    }
   ],
   "source": [
    "for tweet in xlp[\"statuses\"]:\n",
    "    print(tweet.get(\"user\").get(\"name\"), \":\", tweet.get(\"text\"))\n",
    "    print(\"################\")\n",
    "    \n",
    "  \n",
    "    author = np.array(tweet.get(\"user\").get(\"name\"));\n",
    "    print(author)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up data and from companies and place in dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ne‚Ñìs‡πèŒÆüåü\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_data(my_tweets):\n",
    "    tweet_list = []\n",
    "    for i in my_tweets:      \n",
    "\n",
    "        proc_tweet = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\\\n",
    "                        '(?:%[0-9a-fA-F][0-9a-fA-F]))+','',i)\n",
    "\n",
    "        proc_tweet = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", proc_tweet)\n",
    "        print(i)\n",
    "        proc_tweet = proc_tweet.lower()\n",
    "   \n",
    "        proc_tweet = re.sub(r'\\W', ' ', proc_tweet)\n",
    "            \n",
    "        proc_tweet = re.sub(r'\\s+', ' ', proc_tweet, flags=re.I)\n",
    "\n",
    "        proc_tweet = proc_tweet.replace('rt','')\n",
    "\n",
    "        proc_tweet = re.findall(r'\\w+', proc_tweet) \n",
    "        \n",
    "        tweet_list.append(proc_tweet)\n",
    "    \n",
    "    return tweet_list\n",
    "\n",
    "#tweet.get(\"user\").get(\"name\"), \":\", \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "author = np.array(tweet.get(\"user\").get(\"name\"));\n",
    "print(author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply k-means or other appropriate clustering alogrithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(xlp)\n",
    "xlp = api.search(\"google\", count = 10, lang = \"sv\")\n",
    "#api = tweepy.API(auth) \n",
    "tweets = api.user_timeline(screen_name = \"google\",count = 5) \n",
    "\n",
    "\n",
    "#xlp = api.search(\"abb\", count = 10, lang = \"sv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store in CSV files or other for javascript to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@\n",
      "a\n",
      "y\n",
      "e\n",
      "a\n",
      "j\n",
      "a\n",
      "n\n",
      "a\n",
      "b\n",
      "i\n",
      " \n",
      "K\n",
      "i\n",
      "s\n",
      "k\n",
      "a\n",
      " \n",
      "k\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "a\n",
      "b\n",
      "b\n",
      "?\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "df1 = pd.DataFrame(clean_data(tweet.get(\"text\")))\n",
    "df1.to_csv (r'C:\\Users\\Gustav\\Documents\\Lab1-Interactive_visualization\\infovisproj\\visproj\\data\\tweetdata.csv', index = False, header=True)\n",
    "#print(xlp)\n",
    "#print(df1)\n",
    "\n",
    "\n",
    "#test\n",
    "cars = {'Brand': ['Honda civic','Toyota Corolla','Ford Focus','Audi A4'],\n",
    "        'Price': [22000,25000,27000,35000]\n",
    "        }\n",
    "\n",
    "\n",
    "#print(cars)\n",
    "df = pd.DataFrame(cars, columns= ['Brand', 'Price'])\n",
    "\n",
    "#df = pd.DataFrame(clean_data(get.cars))\n",
    "\n",
    "df.to_csv (r'C:\\Users\\Gustav\\Documents\\Lab1-Interactive_visualization\\infovisproj\\visproj\\data\\test.csv', index = False, header=True)\n",
    "#print (df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R\n",
      "T\n",
      " \n",
      "@\n",
      "S\n",
      "v\n",
      "e\n",
      "n\n",
      "s\n",
      "k\n",
      "H\n",
      "o\n",
      "r\n",
      "a\n",
      ":\n",
      " \n",
      "‚Äù\n",
      "E\n",
      "n\n",
      " \n",
      "k\n",
      "v\n",
      "i\n",
      "n\n",
      "n\n",
      "a\n",
      " \n",
      "f\n",
      "r\n",
      "√•\n",
      "n\n",
      " \n",
      "E\n",
      "u\n",
      "r\n",
      "o\n",
      "p\n",
      "a\n",
      "s\n",
      " \n",
      "f\n",
      "a\n",
      "t\n",
      "t\n",
      "i\n",
      "g\n",
      "a\n",
      "s\n",
      "t\n",
      "e\n",
      " \n",
      "l\n",
      "√§\n",
      "n\n",
      "d\n",
      "e\n",
      "r\n",
      " \n",
      "t\n",
      "a\n",
      "r\n",
      " \n",
      "s\n",
      "i\n",
      "g\n",
      " \n",
      "i\n",
      "n\n",
      "t\n",
      "e\n",
      " \n",
      "s\n",
      "j\n",
      "√§\n",
      "l\n",
      "v\n",
      " \n",
      "t\n",
      "i\n",
      "l\n",
      "l\n",
      " \n",
      "e\n",
      "t\n",
      "t\n",
      " \n",
      "h\n",
      "o\n",
      "t\n",
      "e\n",
      "l\n",
      "l\n",
      " \n",
      "i\n",
      " \n",
      "V\n",
      "√§\n",
      "s\n",
      "t\n",
      "e\n",
      "r\n",
      "√•\n",
      "s\n",
      "‚Äù\n",
      ".\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "L\n",
      "o\n",
      "l\n",
      ",\n",
      " \n",
      "d\n",
      "e\n",
      " \n",
      "k\n",
      "o\n",
      "m\n",
      "m\n",
      "e\n",
      "r\n",
      " \n",
      "f\n",
      "r\n",
      "√•\n",
      "n\n",
      " \n",
      "R\n",
      "u\n",
      "m\n",
      "√§\n",
      "n\n",
      "i\n",
      "e\n",
      "n\n",
      ",\n",
      " \n",
      "i\n",
      "‚Ä¶\n",
      "        0\n",
      "0       r\n",
      "1       t\n",
      "2    None\n",
      "3    None\n",
      "4       s\n",
      "..    ...\n",
      "135     n\n",
      "136  None\n",
      "137  None\n",
      "138     i\n",
      "139  None\n",
      "\n",
      "[140 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "def clean_data1(my_tweets):\n",
    "    tweet_list = []\n",
    "    for i in tweet.get(\"text\"):      \n",
    "\n",
    "        proc_tweet = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+#]|[!*\\(\\),]|'\\\n",
    "                        '(?:%[0-9a-fA-F][0-9a-fA-F]))+','',i)\n",
    "\n",
    "        proc_tweet = re.sub(\"(@[A-Za-z0-9_]+)\",\"\", proc_tweet)\n",
    "        print(i)\n",
    "        proc_tweet = proc_tweet.lower()\n",
    "   \n",
    "        proc_tweet = re.sub(r'\\W', ' ', proc_tweet)\n",
    "            \n",
    "        proc_tweet = re.sub(r'\\s+', ' ', proc_tweet, flags=re.I)\n",
    "\n",
    "        proc_tweet = proc_tweet.replace('rt','')\n",
    "\n",
    "        proc_tweet = re.findall(r'\\w+', proc_tweet) \n",
    "        \n",
    "        tweet_list.append(proc_tweet)\n",
    "    \n",
    "    return tweet_list\n",
    "\n",
    "#tweet.get(\"user\").get(\"name\"), \":\", \n",
    "\n",
    "\n",
    "\n",
    "#tweet.get(\"user\").get(\"name\"), \":\", \n",
    "\n",
    "df2 = pd.DataFrame(clean_data1(tweet.get(\"text\")))\n",
    "df2.to_csv (r'C:\\Users\\Gustav\\Documents\\Lab1-Interactive_visualization\\infovisproj\\visproj\\data\\tweetdata.csv', index = False, header=True)\n",
    "#print(xlp)\n",
    "print(df2)\n",
    "\n",
    "#extra ideas, test\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ### Store in csv files or similar  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for tweet in xlp[\"statuses\"]:\n",
    "\n",
    "for x in tweet_data['statuses']:\n",
    "    my_tweets.append(x['full_text'])\n",
    "\n",
    " for i in tweet.get(\"text\"): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Name': ['Miranda'], 'Text': ['RT @SvenskHora: ‚ÄùEn kvinna fr√•n Europas fattigaste l√§nder tar sig inte sj√§lv till ett hotell i V√§ster√•s‚Äù. \\n\\nLol, de kommer fr√•n Rum√§nien, i‚Ä¶']}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'column'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-161-7b5b35c3b173>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclean_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34mr'C:\\Users\\Gustav\\Documents\\Lab1-Interactive_visualization\\infovisproj\\visproj\\data\\test.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'column'"
     ]
    }
   ],
   "source": [
    "\n",
    "for tweet in xlp[\"statuses\"]:\n",
    "        data = {'Name': [tweet.get(\"user\").get(\"name\")] ,\n",
    "                'Text': [tweet.get(\"text\")] } \n",
    "        print(data)\n",
    "        \n",
    "        df = pd.DataFrame(data, column = ['name', 'text'])\n",
    "        df = clean_data(df)\n",
    "        df.to_csv (r'C:\\Users\\Gustav\\Documents\\Lab1-Interactive_visualization\\infovisproj\\visproj\\data\\test.csv', index = False, header=True)\n",
    "        #print (df)\n",
    "        \n",
    "        \n",
    "        cars = {'Brand': ['Honda civic','Toyota Corolla','Ford Focus','Audi A4'],\n",
    "        'Price': [22000,25000,27000,35000]\n",
    "        }\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
